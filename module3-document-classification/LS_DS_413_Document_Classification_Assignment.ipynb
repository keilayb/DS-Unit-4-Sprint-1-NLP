{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to change the path\n",
    "train = pd.read_csv('whiskey-reviews-ds24/train.csv')\n",
    "test = pd.read_csv('whiskey-reviews-ds24/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1321</td>\n      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3861</td>\n      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>655</td>\n      <td>\\nThis release is a port version of Amrut’s In...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>555</td>\n      <td>\\nThis 41 year old single cask was aged in a s...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1965</td>\n      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nThis has the classic sweetish, oily, floral, leathery nose of 100% rye grain whisky. A luxurious, creamy, medium-weight dram with caraway rye bread, restrained but hot peppery spices, vague citrus notes, and hints of cedar setting goal posts for punts of sweet and vaguely floral barley sugar, nail polish (in a good way), caramel, barrel wood, well-aged lumber, dark rye bread, ripe apples, milk chocolate, and baking spices. $90 CAD'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train.description[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up function\n",
    "def clean_descriptions(txt):\n",
    "    \"\"\"\n",
    "    Takes in text, removes end of line character from text.\n",
    "    Returns text with end of line characters removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_txt = re.sub('\\\\n', '', txt)\n",
    "    clean_txt = re.sub('[^a-zA-Z 0-9]', '', clean_txt)\n",
    "\n",
    "    return clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  Sometimes when whisky is batched a few leftove...               1\n",
       "1  3861  An uncommon exclusive bottling of a 6 year old...               0\n",
       "2   655  This release is a port version of Amruts Inter...               1\n",
       "3   555  This 41 year old single cask was aged in a she...               1\n",
       "4  1965  Quite herbal on the nose with aromas of dried ...               1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1321</td>\n      <td>Sometimes when whisky is batched a few leftove...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3861</td>\n      <td>An uncommon exclusive bottling of a 6 year old...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>655</td>\n      <td>This release is a port version of Amruts Inter...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>555</td>\n      <td>This 41 year old single cask was aged in a she...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1965</td>\n      <td>Quite herbal on the nose with aromas of dried ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train['description'] = train['description'].apply(clean_descriptions)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['description']\n",
    "y = train['ratingCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 4 folds for each of 216 candidates, totalling 864 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (None, 20, 40),\n",
       "                         'clf__n_estimators': (10, 100, 150),\n",
       "                         'vect__max_df': (0.8, 0.85, 0.9),\n",
       "                         'vect__max_features': (3000, 3500, 3750, 4000),\n",
       "                         'vect__min_df': (0.05, 0.1)},\n",
       "             verbose=10)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "params = {\n",
    "    'vect__max_df': (0.80, 0.85, .90),\n",
    "    'vect__min_df': (.05, .10), \n",
    "    'vect__max_features': (3000, 3500, 3750, 4000), \n",
    "    'clf__n_estimators': (10, 100, 150), \n",
    "    'clf__max_depth': (None, 20, 40)\n",
    "}\n",
    "\n",
    "# create gridsearch object\n",
    "gs = GridSearchCV(pipe, params, cv=4, n_jobs=-1, verbose=10)\n",
    "\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7367262050403719"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# get baseline\n",
    "baseline_acc = y.sum()/len(y)\n",
    "baseline_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7183754655176711"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'clf__max_depth': 40,\n",
       " 'clf__n_estimators': 100,\n",
       " 'vect__max_df': 0.8,\n",
       " 'vect__max_features': 3000,\n",
       " 'vect__min_df': 0.05}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = gs.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2604</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3341</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3764</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2306</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1022 entries, 0 to 1021\nData columns (total 2 columns):\n #   Column          Non-Null Count  Dtype\n---  ------          --------------  -----\n 0   id              1022 non-null   int64\n 1   ratingCategory  1022 non-null   int64\ndtypes: int64(2)\nmemory usage: 16.1 KB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'whiskey-reviews-ds24/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 80% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data transformers\n",
    "svd = TruncatedSVD()\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# create classifier\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# instantiate pipeline object\n",
    "lsa_pipe = Pipeline([('vect', tfidf), # data transformer\n",
    "                ('svd', svd)])   # data transformer 2\n",
    "\n",
    "pipe = Pipeline([('lsa', lsa_pipe),   # data transformer\n",
    "                 ('clf', rfc)])  # classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('lsa',\n",
       "                                        Pipeline(steps=[('vect',\n",
       "                                                         TfidfVectorizer(stop_words='english')),\n",
       "                                                        ('svd',\n",
       "                                                         TruncatedSVD())])),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'clf__max_depth': (None, 10),\n",
       "                         'clf__n_estimators': (10, 100),\n",
       "                         'lsa__svd__n_components': (10, 100),\n",
       "                         'lsa__vect__max_df': (0.8, 0.85, 0.9)},\n",
       "             verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "params = {\n",
    "    \"lsa__svd__n_components\": (10, 100), \n",
    "    \"lsa__vect__max_df\": (0.80, 0.85, 0.90),\n",
    "    \"clf__n_estimators\": (10, 100), \n",
    "    \"clf__max_depth\": (None, 10)  \n",
    "                               }\n",
    "\n",
    "gs_lsa = GridSearchCV(pipe, params, cv=5, n_jobs=4, verbose=1)\n",
    "gs_lsa.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7247392661445506"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "gs_lsa.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'clf__max_depth': 10,\n",
       " 'clf__n_estimators': 10,\n",
       " 'lsa__svd__n_components': 100,\n",
       " 'lsa__vect__max_df': 0.8}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "gs_lsa.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = gs_lsa.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2604</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3341</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3764</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2306</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'whiskey-reviews-ds24/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    \"\"\"\n",
    "    This serves as both our tokenizer and vectorizer.\n",
    "    Returns a nested list of word vectors (i.e. our doc-term matrix).\n",
    "    \"\"\"\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our function to create our doc vectors \n",
    "X_train_vect = get_word_vectors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "embedding_pipe = Pipeline([('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('clf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (None, 10, 40),\n",
       "                         'clf__max_features': ('auto', 0.5, 0.8),\n",
       "                         'clf__n_estimators': (100, 150, 200)},\n",
       "             verbose=15)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \n",
    "    'clf__max_depth' : (None, 10, 40),\n",
    "    'clf__n_estimators': (100, 150, 200),\n",
    "    'clf__max_features': ('auto', 0.5, 0.8)\n",
    "}\n",
    "\n",
    "gs_embedding = GridSearchCV(embedding_pipe, param_dist, cv=3, n_jobs=-1, verbose=15)\n",
    "\n",
    "gs_embedding.fit(X_train_vect, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7403965870971473"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "gs_embedding.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'clf__max_depth': None, 'clf__max_features': 0.5, 'clf__n_estimators': 200}"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# THIS ONE IS MY BEST SUBMISSION --- SAVED AS submission3.csv\n",
    "gs_embedding.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['description'] = test['description'].apply(clean_descriptions)\n",
    "X_test_clean = test.description\n",
    "X_test_vect = get_word_vectors(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = gs_embedding.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2604</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3341</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3764</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2306</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'whiskey-reviews-ds24/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 80% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  },
  {
   "source": [
    "1. Sentiment Analysis\n",
    "- Sentiment Analysis is using NLP, text analysis, and other technologies to identify, extract, quantify, and study people's moods and subjective information.\n",
    "- Document Classification is not the same thing as Sentiment Analysis. Document Classification  \"labels\" documents by topic, whereas Sentiment Classification does more than just labelling.\n",
    "- We classify words as positive, negative, or neutral. We could also use Lexicon, which already has words labelled.\n",
    "- Common applications of Sentiment Analysis are monitoring social media and to analyze customer feedback."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python390jvsc74a57bd031573d84b2a5682177834a321af42eea648d9a4417564de6bd7841ec3642bc80",
   "display_name": "Python 3.9.0 64-bit ('DS-Unit-4-Sprint-1-NLP': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}